{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch-GPU",
      "language": "python",
      "name": "pyt-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of Lecture_8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pDnSshCXD-ZL",
        "2JDTirUfD-Zf",
        "vICVTE1wD-Zq",
        "wDNQLaL6D-Zu",
        "hNbj9oDlD-aS",
        "3kRdaQe6D-ab",
        "5t7iYj2eD-an",
        "tRlkcpT0D-a1",
        "ROmpaSMVD-bA",
        "VY6m7c0qD-bQ"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VNIH93hD-Ya",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 8 - PyTorch\n",
        "\n",
        "This will be the final lecture, today we will first have a brief introduction of deep learning, then we will look at some basics of using PyTorch to implement some simple models in deep learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fCZYu2D-Yc",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning Libraries\n",
        "\n",
        "There are many deep learning libraries available, the most common ones for python are\n",
        "\n",
        "- TensorFlow, Keras\n",
        "- PyTorch\n",
        "\n",
        "Working with tensorflow requires going into lot of details of the contruction of the computation graph, whereas Keras is a higher level interface for tensorflow. Tensorflow is very popular in the industry and good for production code.\n",
        "\n",
        "PyTorch can be used as low level interface, but is much more user-friendly than tensorflow, but it also has a higher level interface. Pytorch is more popular in the research community."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUDYHi8D-Yd",
        "colab_type": "text"
      },
      "source": [
        "## Main features that any deep learning library should provide\n",
        "\n",
        "No matter what library or language you use, the main features provided by a deep learning library are \n",
        "1. Use the GPU to speed up computation \n",
        "2. Ability to do automatic differentiation\n",
        "3. Useful library functions for common architectures and optimization algorithms\n",
        "\n",
        "### PyTorch\n",
        "We will look at all of the above in pytorch.\n",
        "The best way to think about pytorch is that its numpy + GPU + autograd.\n",
        "\n",
        "You can install it with\n",
        "\n",
        "```conda install pytorch```.\n",
        "\n",
        "Alternatively (and recommended), run this notebook in Google Colab-- it provides an environment with all of the PyTorch dependencies plus a GPU free of charge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdvNHW0D-Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpWzZewHD-Yi",
        "colab_type": "text"
      },
      "source": [
        "The equivalent object to numpy arrays in pytorch are called tensors, but they are just multidimensional arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78yenP1D-Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.tensor([2,3,4,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efg1UeizD-Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.zeros((5,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BlufhDpD-Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones((5,5))\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgFdW_4D-Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2*x + 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwCz7O1wD-Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.randn(5,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fHiY5VKD-Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand(25)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QKyI7hD-Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=x.reshape(-1,5)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLKjs14-D-Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9fwJoSD-Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(torch.arange(10))\n",
        "print(torch.eye(5))\n",
        "print(torch.linspace(0,1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cix7EXwSD-Y7",
        "colab_type": "text"
      },
      "source": [
        "Some functions are a bit different"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BukQIL5D-Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.rand(5,5)\n",
        "#or A = torch.rand((5,5))\n",
        "x = torch.ones(5,1)\n",
        "#x = torch.rand((5,1))\n",
        "A@x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6YHvvy4D-Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.random.rand(5,5)\n",
        "x = np.ones((5,1))\n",
        "A@x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpEwcH-JD-ZA",
        "colab_type": "text"
      },
      "source": [
        "You can convert tensors to a numpy array that shares its memory with the pytorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MquNPK71D-ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones(5,5)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOeMqFrOD-ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xn = x.numpy()\n",
        "xn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZlG0x9xD-ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xn[4,2]=10\n",
        "xn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN6qJIsID-ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDnSshCXD-ZL",
        "colab_type": "text"
      },
      "source": [
        "### Using the GPU\n",
        "\n",
        "The GPU (Graphical Processing Unit) is a separate processing unit that is specialized to handle bulk computations required for rendering high quality graphics. It mainly consists of a large number of processor cores that are individually very slow, but because of their sheer number (around 2000) they can churn through computations very quickly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJ0hjO5D-ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kadMeJD-ZN",
        "colab_type": "text"
      },
      "source": [
        "Installing the GPU drivers and the CUDA toolkit can be quite messy, so if you just want to experiment with GPUs and deep learning libraries, you can use [Google colaboratory](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtE0kLaD-ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = torch.device(\"cuda\")\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESIE5J08D-ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.rand(100,100)\n",
        "B = torch.rand(100,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VNz5SzD-ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A@B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjtNNqtD-ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A_gpu = A.to(gpu)\n",
        "B_gpu = B.to(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krIHa3ErD-ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A_gpu@B_gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sox7ng2OD-ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A@B_gpu #this won't work!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oi8M-GD-Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C_gpu = A_gpu@B_gpu\n",
        "C = C_gpu.to(cpu)\n",
        "C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JDTirUfD-Zf",
        "colab_type": "text"
      },
      "source": [
        "### GPU - CPU memory transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc4PxyqTD-Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_mat = torch.rand(20000,20000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0StFx6D-Zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_mat_gpu = big_mat.to(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEI_-PmOD-Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big_mat= big_mat_gpu.to(cpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx6a7G8UD-Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del big_mat_gpu\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUt6M95HD-Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del big_mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vICVTE1wD-Zq",
        "colab_type": "text"
      },
      "source": [
        "## Speedup from GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4raRnuw1D-Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000)\n",
        "B = torch.rand(3000,3000)\n",
        "C = torch.zeros(3000,3000)\n",
        "C.copy_(B)\n",
        "for i in range(5):\n",
        "    C=torch.mm(A,C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch47eB6OD-Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit\n",
        "A = torch.rand(3000,3000, device = gpu)\n",
        "B = torch.rand(3000,3000, device = gpu)\n",
        "C = torch.zeros(3000,3000, device = gpu)\n",
        "C.copy_(B)\n",
        "for i in range(5):\n",
        "    C=torch.mm(A,C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDNQLaL6D-Zu",
        "colab_type": "text"
      },
      "source": [
        "## Automatic Differentiation\n",
        "\n",
        "PyTorch uses dynamic computation graphs to compute the gradients of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r6mfgjHD-Zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "m = torch.tensor([5.0], requires_grad = True)\n",
        "c = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezGUNqXD-Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = m*x + c\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_Y_WzasD-Z0",
        "colab_type": "text"
      },
      "source": [
        "Define an error for your function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7oYMHFD-Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuhWukrD-Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMhtVXAhD-Z5",
        "colab_type": "text"
      },
      "source": [
        "Calling `x.backward()` on any tensor forces pytorch to compute all the gradients of the tensors used to compute `x` which had the `requires_grad` flag set to `True`. The computed gradient will be stored in the `.grad` property of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PIU90uoD-Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYbns6g4D-Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYesARFD-Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDhPOJHRD-aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    m -= 0.01 * m.grad\n",
        "    c -= 0.3 * c.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlUBDHaD-aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m,c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj85MTj2D-aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.grad, c.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3UbDFA7D-aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m.grad.zero_()\n",
        "c.grad.zero_()\n",
        "\n",
        "m.grad, c.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgA5bqxD-aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = m*x + c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhEnrtmQD-aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJYE5aRpD-aO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = torch.norm( y - 13)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBLYqopxD-aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()\n",
        "m.grad, c.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNbj9oDlD-aS",
        "colab_type": "text"
      },
      "source": [
        "### Making it more compact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlQ60VuqD-aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(x,m,c):\n",
        "    return m*x + c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZHeiwJD-aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7drmZAzD-aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = torch.tensor([5.0], requires_grad = True)\n",
        "c = torch.tensor([2.0], requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSogMXf-D-aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([2.0])\n",
        "yt = torch.tensor([13.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77BNsdU-D-aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model_fn(x,m,c)\n",
        "loss = loss_fn(y,yt)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "    m -= 0.05 * m.grad\n",
        "    c -= 0.05 * c.grad\n",
        "m.grad.zero_()\n",
        "c.grad.zero_()\n",
        "\n",
        "print( f\" m = {m}\\n c = {c}\\n y = {y}\\n loss = {loss}\")\n",
        "#note that 'loss' indicates the loss for the previous m,c values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kRdaQe6D-ab",
        "colab_type": "text"
      },
      "source": [
        "### Slightly more complicated problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alq94bPxD-ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdYDtWDD-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(x,m,c):\n",
        "    return m@x + c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Cvos0BD-af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(y,yt):\n",
        "    return torch.norm(y-yt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCjbW7HD-ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = torch.rand((5,5), requires_grad = True)\n",
        "c = torch.ones((5,1), requires_grad = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsITRCClD-ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(5,100)\n",
        "yt = torch.randn(1,100)\n",
        "losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFs5CphAD-al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1000):\n",
        "  y = model_fn(x,m,c)\n",
        "  loss = loss_fn(y,yt)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "      m -= 0.05 * m.grad\n",
        "      c -= 0.05 * c.grad\n",
        "  m.grad.zero_()\n",
        "  c.grad.zero_()\n",
        "\n",
        "  losses+=[loss.item()]\n",
        "  print( f\"loss = {loss}\")\n",
        "  plt.plot(losses);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7iYj2eD-an",
        "colab_type": "text"
      },
      "source": [
        "## Using Library functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xg-kywmD-an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(5, 5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(5, 5),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OocRUb9D-ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgBOzYv5D-aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bdGByKKD-as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(100,5)\n",
        "yt = torch.randn(100,1)\n",
        "losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KupJGFEFD-at",
        "colab_type": "text"
      },
      "source": [
        "Using the optim package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ac8_-reD-au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqRB-phKD-aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.optim."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtdxXUcRD-az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1000):\n",
        "    y = model(x)\n",
        "    loss = loss_fn(y,yt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRlkcpT0D-a1",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4GfdMRhD-a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyQ4gP46D-a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = MNIST(\".\",download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdfX2XnGD-a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fwSvMkD-a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "img,y = data[np.random.randint(1,60000)]\n",
        "print(y)\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3giZTnRiD-a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.train_data[2].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsZHdAMlD-a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.train_labels[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROmpaSMVD-bA",
        "colab_type": "text"
      },
      "source": [
        "### MNIST Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHhKarpfD-bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(784, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100, 10),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8Q59QCED-bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehneQZatD-bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "yt = data.train_labels[sample]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucZS9UPAD-bJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape,yt.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdOxW-tYD-bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
        "losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtNhgaED-bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    sample = np.random.choice(range(len(data.train_data)),1000)\n",
        "    x = data.train_data[sample].reshape(1000,-1).float()/255\n",
        "    yt = data.train_labels[sample]\n",
        "    \n",
        "    y = model(x)\n",
        "    loss = loss_fn(y,yt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    losses+=[loss.item()]\n",
        "    #print( f\"loss = {loss}\")\n",
        "plt.plot(losses);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAXeaKHD-bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = data.train_data[-1000:].reshape(1000,-1).float()/255\n",
        "y_test = data.train_labels[-1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VXFOBCjD-bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0c-JhpD-bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy = \", (y_pred.argmax(dim=1) == y_test).sum().float().item()/1000.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6m7c0qD-bQ",
        "colab_type": "text"
      },
      "source": [
        "## Course Conclusion\n",
        "\n",
        "By now you should have a sufficient introduction to the various ways one can use python for scientific computing. The best way to learn more is to start using python for whatever project you are working on. Only practice will make you comfortable with using python.\n"
      ]
    }
  ]
}